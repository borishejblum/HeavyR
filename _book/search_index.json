[
["index.html", "Formation R avancée Présentation de la formation", " Formation R avancée Outils de développement et de performance Robin Genuer et Boris Hejblum 2018-04-11 Présentation de la formation Le but principal de cette formation est de vous donner des outils pour faciliter le développement de code (performant) avec R. L’aspect “performance” arrivera dans un deuxième temps, et les premiers outils présentés sont également très utiles dans des situations ne faisant pas intervenir de temps de calculs importants. Nous allons centrer la présentation de ces outils de développement autour de la notion de package. Vous connaissez déjà cette notion, car vous avez déjà installer des packages depuis le CRAN par exemple. Vous savez également que c’est le moyen le plus standard dans R pour mettre à disposition du code. Nous allons vous montrer que le package est également un excellent outil pour développer le code. Nous allons adopter le plan suivant : Construire un package Tracer les changements, partager son code, développement collaboratif et automatiser les tests dans un package Mesurer le temps de calcul Profiler le code Utiliser Rcpp pour optimiser ce qui doit l’être Paralléliser facilement le code Afin de suivre cette formation, il est nécessaire de disposer des logiciels suivants : la dernière version de R (v3.4.3 - https://cloud.r-project.org/) la dernière version de RStudio (v1.1.423 - https://www.rstudio.com/products/rstudio/download/#download) un compilateur C++ (tel que gcc ou clang - natif sous les système UNIX, pour les utilisateurs Windows nous recommandons l’installation de Rtools, pour les utilisateurs Mac il peut être nécessaire d’installer les outils de développement Apple comme suggéré ici) les packages R suivants : devtools, doParallel, itertools, microbenchmark, profvis, Rcpp, RcppArmadillo, roxygen2, testthat, mvtnorm le client GitHub Desktop le logiciel git "],
["construire-un-package-r.html", "1 Construire un package R 1.1 Initialiser un package 1.2 Ajouter une fonction : exemple fil rouge 1.3 Documenter une fonction 1.4 Tester le package de manière intéractive 1.5 Tester le package de manière automatique 1.6 Faire un check du package 1.7 Installer le package 1.8 Annexe 1.1 : ajouter d’une méthode S3 1.9 Annexe 1.2 : soumettre son package au CRAN", " 1 Construire un package R Nous présentons ici comment construire un package efficacement à l’aide d’outils graphiques présents dans Rstudio et du package devtools. Le site de référence sur ce sujet est le site R packages d’Hadley Wickham. 1.1 Initialiser un package Une manière simple, et intégrée à Rstudio, pour initialiser un package est : de créer un nouveau projet (menu déroulant en haut à droite dans Rstudio) choisir “New Directory” choisir “R package using devtools” (s’il n’est pas disponible, choisir “R package”, différence étant qu’avec “R package”, il faudra supprimé des fichiers créés automatiquement mais non utiles) donner un nom au package, par exemple mypkgr On récupère la structure minimale pour un package R, à savoir : un fichier DESCRIPTION dont les parties Title, Version, Authors@R et Description sont à éditer (d’autres parties pourront être éditer voire même ajouter de manière automatique, voir plus loin) un fichier NAMESPACE qui sera éditer automatiquement plus loin un dossier R dans lequel on va ajouter des fichiers de scripts R Rstudio ajoute également trois fichiers facultatifs : .gitignore, relatif à git, outils de contrôle de version que nous verrons en détails dans la partie sur GitHub mypkgr.Rproj qui est un fichier spécifique de Rstudio, et permet de définir les caractéristiques et préférences du projet que nous venons de créer .Rbuildignore qui permet d’ignorer certains fichiers au moment où on construira le package un peu plus loin (par exemple, le fichier mypkgr.Rproj ne doit pas être inclus dans le package) 1.2 Ajouter une fonction : exemple fil rouge Nous vous proposons de coder la fonction suivante, que nous reprendrons tout au long de la formation : Nous souhaitons calculer la valeur de la densité d’une loi normale multivariée sur \\(\\mathbb{R}^p\\) en \\(n\\) points. Notre fonction doit pouvoir s’appliquer pour n’importe quelle loi normale multivariée (vecteur de moyennes dans \\(\\mathbb{R}^p\\) et matrice de variance-covariance d’ordre de \\(p\\) quelconques), et on souhaite pouvoir calculer toutes les valeurs de la densité évaluées sur les \\(n\\) points en un seul appel de la fonction. Vous devez donc créer une fonction mvnpdf() dans un fichier nommé mvnpdf.R dans le dossier R du package, qui : prend en arguments : x une matrice, à \\(n\\) colonnes (les observations) et \\(p\\) lignes mean un vecteur de moyennes varcovM une matrice de variance-covariance Log un paramètre logique valant TRUE par défaut renvoie une liste contenant la matrice x ainsi qu’un vecteur des images des points de x par la fonction de densité de la variable aléatoire de loi normale multivariée considérée. A vous de jouer ! ATTENTION ! Si vous cliquez trop vite sur le lien ci-dessous, cela invalidera votre participation à la formation ! Voici une proposition de fonction que vous pouvez télécharger ici. Pour des conseils lors de la rédaction de code, voir la page R code du site d’Hadley. 1.3 Documenter une fonction Il est important de bien documenter votre code. Tout projet a au moins 2 développeurs : vous vous dans 6 mois Par égard à votre futur moi, soyez sympas et prenez le temps de documenter votre code ! Nous vous conseillons vivement d’utiliser le package roxygen2 pour documenter vos packages. L’avantage principale étant d’avoir l’aide d’une fonction dans le même fichier que le code définissant cette fonction. A vous de jouer ! Commencer par insérer le squelette de l’aide grâce à “Insert Roxygen Skeleton” situé dans le menu “Code” ou le sous-menu Baguette magique Compléter la documentation en renseignant : le titre de la fonction (première ligne) la description de ce que fait la fonction (deuxième paragraphe) si vous renseignez un troisième paragraphe, cette partie ira dans la section “Details” de la page d’aide la signification des paramètres la sortie, après la balise @return Générer la documentation à l’aide de “Document” dans le menu “More” de l’onglet “Build” (ou Ctrl+Shift+D ou devtools::document()). L’effet de cette commande est multiple : un dossier man a été créé et à l’intérieur, un fichier mvnpdf.Rd a été créé et contient les informations de l’aide de la fonction le fichier NAMESPACE a été modifié En cas de bug ou par curiosité ET une fois que vous avez terminé vous pouvez consulter cette proposition. Pour plus de détails sur la documentation de package et les balises roxygen2, voir la page Object documentation du site d’Hadley. Finissons par évoquer une fonction du package devtools qui initialise une page d’aide pour le package dans son ensemble : devtools::use_package_doc() La page d’aide générée sera alors accessible, une fois le package installé, via : ?mypkgr 1.4 Tester le package de manière intéractive Pour tester le package, vous devez le charger dans R à l’aide de : dans l’onglet “Build”, le menu “More” puis “Load All” (ou Ctrl+Shift+L ou devtools::load_all()). Vous pouvez alors utiliser votre package directement dans R : consulter l’aide de la fonction avec ?mvnpdf et par exemple exécuter les commandes renseignées dans la section exemple de cette page d’aide. ?mvndpf Ainsi, lors du développement, vous pouvez : Ajouter/Modifier le code R Re-charger le package Ctrl+Shift+L Essayer dans la console Et ainsi de suite… 1.5 Tester le package de manière automatique Pour initialiser la fonctionnalité de tests automatiques dans le package, utiliser : devtools::use_testthat() Cette commande induit la création d’un dossier tests qui comprend un fichier testthat.R - à ne pas modifier - et un dossier testthat dans lequel on va insérer nos tests. Cet outils s’appuie sur la théorie des tests unitaires. Voici par exemple, le contenu d’un fichier qu’on appellera test-univariate.R à mettre dans le dossier testthat : context(&quot;Univariate gaussian test&quot;) test_that(&quot;correct result for univariate gaussian&quot;, { expect_equal(mvnpdf(x=matrix(1.96), Log=FALSE)$y, dnorm(1.96)) expect_equal(mvnpdf(x=matrix(c(1.96, -0.5), ncol = 2), Log=FALSE)$y, dnorm(c(1.96, -0.5))) }) Et un deuxième, appelé test-bivariate.R : context(&quot;Bivariate gaussian test&quot;) test_that(&quot;correct results for bivariate gaussian&quot;, { expect_equal(mvnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1), Log=FALSE)$y, mvtnorm::dmvnorm(rep(1.96, 2))) }) Pour exécuter ces tests, on peut utiliser dans l’onglet “Build”, le menu “More”, “Test package” (ou devtools::test() ou Ctrl+Shift+T). L’avantage de ces tests automatiques est qu’ils vont s’exécuter à chaque fois qu’on effectuera un check du package. Une bonne pratique est d’ajouter un test unitaire à chaque fois qu’un bug est identifier et résolu, afin de pouvoir immédiatement identifier et prévenir qu’une erreur identique ne se reproduise dans le futur. 1.6 Faire un check du package Faire un check signifie vérifier que tout est correct dans le package. Il est nécessaire de “passer” le check pour pouvoir déposer le package sur le CRAN. Pour exécuter celui-ci, utiliser “Check” dans l’onglet “Build” (devtools::check() ou Ctrl+Shift+E). Lors du check, les tests que nous avons mis au point précédemment sont exécutées. C’est justement l’avantage d’avoir fait ces tests, nous n’avons plus besoin de s’en préoccuper, mais juste de réagir en cas d’erreurs renvoyées. 1.7 Installer le package Pour le moment, le package n’existe que dans l’environnement associé au projet Rstudio qu’on a créé. Pour pouvoir l’utiliser dans R de manière générale, il faut l’installer (comme un package du CRAN par exemple). Pour faire ça, utiliser “Install and Restart” dans l’onglet “Build” (devtools::install() ou Ctrl+Shift+B). Et enfin, vous pouvez configurer le comportement de Rstudio pour qu’au moment de l’installation, il documente en même temps le package : aller dans l’onglet “Build”, le menu “More” puis “Configure Build Tools”. Cliquer ensuite sur “Configure” puis cocher la case en bas “Build and Reload”. 1.8 Annexe 1.1 : ajouter d’une méthode S3 Dans la plupart des packages on est amenés à implémenter des méthodes S3, très souvent pour qu’à partir d’un objet résultat res, on puisse exécuter print(res), summary(res), plot(res)… Voici un exemple de méthode plot() qu’on peut ajouter dans notre package : #&#39; Plot of the mvnpdf function #&#39; #&#39; @param x an object of class \\code{mvnpdf} resulting from a call of #&#39; \\code{mnvpdf()} function. #&#39; @param ... graphical parameters passed to \\code{plot()} function. #&#39; #&#39; @return Nothing is returned, only a plot is given. #&#39; @export #&#39; #&#39; @examples #&#39; pdfvalues &lt;- mvnpdf(x=matrix(seq(-3, 3, by = 0.1), nrow = 1), Log=FALSE) #&#39; plot(pdfvalues) plot.mvnpdf &lt;- function(x, ...) { plot(x$x, x$y, type = &quot;l&quot;, ...) } Attention ! Pour que cette méthode fasse bien ce qu’on veut quand on l’applique au résultat de notre fonction mvnpdf(), il faut déclarer que ce résultat est de classe mvnpdf. Tester cette fonction, en exécutant l’exemple. N’oubliez pas de re-charger le package (Ctrl+Shift+L), et de re-documenter le package (Ctrl+Shift+D). Consulter le contenu du dossier man et les modifications qui ont été apportées au fichier NAMESPACE. Voici une proposition de solution : le fichier contient le code complet de la fonction mvnpdf() et de la méthode plot() associée. 1.9 Annexe 1.2 : soumettre son package au CRAN devtools::check_cran() puis devtools::submit_cran() "],
["controle-de-version-avec-git-et-github-hitorique-de-changement.html", "2 Contrôle de version avec git et GitHub : hitorique de changement, 2.1 Principe du contrôle de version 2.2 Utiliser git localement depuis RStudio 2.3 GitHub 2.4 Collaboration pour la production du code 2.5 Intégration continue 2.6 Annexe 2.1 : couverture du code", " 2 Contrôle de version avec git et GitHub : hitorique de changement, développement collaboratif et intégration continue. Nous nous intéressons ici aux solutions proposées par RStudio et GitHub pour l’hébergement et le contrôle de version de projets. 2.1 Principe du contrôle de version Le principe du contrôle de version est d’enregistrer les changements successifs apportés à des fichiers (notamment des fichiers R). RStudio propose 2 solutions intégrées pour le contrôle de version : git svn 2.1.1 git git est un logiciel de contrôle de version (c’est-à-dire un outils qui va enregistrer l’histoire des changements successifs de votre code et permettre de partager ces changements avec d’autres personnes). git est un logiciel en ligne de commande, et sa prise en main n’est pas nécessairement intuitive. git fonctionne de la façon suivante : sur un serveur dans le ‘cloud’, une version à jour du code est disponible. À tout moment il est possible d’accéder à cette version du code en ligne. Chaque contributeur peut télécharger cette dernière version à jour (dans une action que l’on dénomme pull), avant de l’éditer localement. Une fois ses changements effectués, le contributeur peut alors mettre à jour la version en ligne du code afin que ses changements soient disponibles pour tout le monde (dans une action que l’on dénomme push) NB : git a été pensé pour des fichiers légers (comme par exemple des fichiers texte) et est loin d’être optimisé pour des fichiers trop lourds et/où compressés. 2.1.2 subversion subversion est l’autre solution disponible dans RStudio. Elle fonctionne de manière similaire à git, mais avec des fonctionnalités un peu plus réduites que nous détaillons pas ici (la différence majeure est que tout les contributeurs travaillent simultanément sur la même version du code). 2.2 Utiliser git localement depuis RStudio A vous de jouer ! Commencez par activer git depuis l’onglet “Git/SVN” de “Project Options” situé dans le menu “Tools” et suivre les instructions. À partir de l’onglet “Git” maintenant apparu à côté de l’onglet “Build”, enregistrer l’état actuel de votre package en réalisant votre premier “commit” à partir de l’onglet “Git” maintenant apparu à côté de l’onglet “Build”, enregistrer l’état actuel de votre package en réalisant votre premier “commit” : 3a. sélectionner les fichiers à suivre (ne pas sélectionner le fichier .Rpoj) 3b. écrire un message informatif (pour vos collaborateurs - ce qui inclut votre futur vous) 3c. cliquer sur “Commit” ajouter une ligne “*.Rproj&quot; au fichier “.gitignore” et effectuez un nouveau commit visualiser les changements et leur historique à l’aide des outils de visualisation “Diff” et “History” accessible depuis l’onglet “Git” 2.2.1 Bonnes pratiques du commit Idéalement, chaque commit ne devrait régler qu’un seul problème. Il devrait le régler dans son intégralité (être complet) et ne contenir des changements relatifs qu’uniquement à ce problème (être minimal). Il est alors important d’écrire des message de commit informatifs (pensez à vos collaborateur, qui incluent votre futur vous). Il faut également être concis, et décrire les raisons des changements plutôt que les changements eux-mêmes (visibles dans le Diff). Il est parfois difficile de respecter ces directives à la lettre, et celles-ci ne sont qu’un guide et ne doivent pas vous empêcher d’effectuer des commits réguliers. Par ailleurs, la tentation d’avoir un historique de changements “propre” et bien ordonné est naturelle, mais se révèle une source de problèmes inutiles. Elle entre en contradiction avec l’objectif de traçabilité du contrôle de version. Le développement de code étant généralement un processus intellectuel complexe et non linéaire, il est normal que l’enregistrement des changements reflète ce cheminement. En pratique, votre futur-vous sera le premier utilisateur de votre historique de changements et la priorité est donc de vous faciliter la tache dans le futur lors de la résolution de bug où l’extension de fonctionnalités. 2.3 GitHub GitHub est un site internet proposant une solution d’hébergement de code en ligne, et s’appuyant sur git. Il existe de nombreux sites web et services (gitlab, bitbucket, …) permettant d’héberger du code et s’appuyant sur git. GitHub est très populaire dans la communauté des développeurs R, et est relativement facile à utiliser, même pour un utilisateur novice. Les avantages d’utiliser GitHub : une interface graphique simple pour suivre l’historique des changements de votre code la dernière version de développement de votre code est disponible en ligne et vous pouvez la référencer (on peut même référencer un numéro de commit précis pour geler une version spécifique du code) les utilisateurs disposent d’un canal clair et transparent pour signaler les bugs/difficultés cela facilite grandement le développement collaboratif 2.3.1 Mettre son package R sur GitHub A vous de jouer ! rendez vous sur le site https://github.com/ et créez vous un compte GitHub (si vous hésitez, une convention courante est d’utiliser prénomnom comme nom d’utilisateur) ouvrez le client “GitHub desktop” sur votre machine et connectez vous à votre compte GitHub. ajouter un nouveau projet local en cliquant sur l’icone “+” en haut à gauche de la fenêtre du client, puis en choississant “Add” et en rentrant le chemin du dossier où se trouve le code de votre package. une fois le repertoire créer en local, publiez le sur GitHub en cliquant sur “Publish” en haut à droite de la fenêtre du client. Vérifiez sur le site de GitHub que votre code à bien été uploadé avec les 2 commits précédents. Ajouter un fichier “README.Rmd” à votre package afin de disposer d’une belle page d’accueil sur GitHub : 5a. dans RStudio, executez la commande devtools::use_readme_rmd() 5b. à l’aide de l’outilds “Diff” de l’onglet “Git” de RStudio, étudier les changements opérer par la commande précédente 5c. éditez le fichier “README.Rmd” créé, puis créer le fichier README.md correspondant en executant knitr (cliquer su la pelotte de laine “Knit” en haut à gauche dans Rstudio), avant d’effectuer un 3e commit contenant ces changements 5d. à ce stade, si vous visitez la page de votre répertoire sur GitHub, votre 3e commit n’apparait pour l’instant pas. Il faut synchroniser le répertoire GitHub en ligne avec votre dossier local. Pour cela, vous avez 2 solutions : soit utiliser le bouton “Sync” en haut à droit de la fenêtre du client GitHub desktop ; soit directement depuis RStudio en cliquant sur “Push” depuis l’onglet “Git”. Maintenant, les changement du 3e commit sont visibles en ligne dur GitHub. 2.4 Collaboration pour la production du code git et GitHub sont particulièrement efficaces lorsque plusieurs personnes collabore pour développer un code. En effet, chacun peut effectuer des pull et push successifs pour apporter des changements au code, de manière simultanée et en étant sûr de toujours travailler sur la dernière version. Nous allons voir différents concepts utiles dans le cas d’un tel travail collaboratif. A vous de jouer ! En formant des groupes de 2, vous allez chacun ajouter votre binome comme “collaborator” à votre repertoire GitHub à partir de l’onglet “Settings” (sur GitHub). Quelques instants plus tard le collaborateur ainsi ajouté reçoit un email l’invitant à accepter l’ajout. Cliquer sur le lien et accepter. Dans le client “GitHub desktop”, ajouter le répertoire de votre binôme en cliquant sur l’icone “+” en haut à gauche et en selectionnant “Clone”, ce qui fait apparaitre la liste des repertoires associés à votre compte GitHub non liés à un dossier local. Sélectionner le projet de votre binome. 2.4.1 Branches Une des fonctionnalités assez utile de git est les branches. Cela permet d’opérer des changements importants dans le code sans perturber le fonctionnement actuel. C’est notamment utile pour explorer une piste de développement dont on ne sait pas si elle sera concluante au final. D’ailleurs, vous utilisez déjà les branches depuis le depuis de cette partie. En effet, la branche par défaut est appelé “master”. Grâce à ce système de branches, on obtient un arbre des différents commits au cours du temps (où les nœuds correspondent à la séparations des branches). 2.4.2 Merge Un pull se décompose en 2 actions de la part de git : tout d’abord un fetch, qui correspond au téléchargement du code en ligne suivi d’un merge qui fusionne la version locale avec les changements. Après avoir conduit un développement expérimental dans une branche, on peut vouloir merger ces changements dans la branche “master” par exemple, après que l’expérience se soit révélée concluante.&quot; Si un les changements concernent des parties distinctes du code, alors le merge peut s’effectuer sans problème. En revanche si les 2 versions à merger comportent des changements depuis leur dernier “commit* commun qui concerne les mêmes lignes de codes, alors on va rencontrer un (ou des ) conflit(s), qu’il va falloir résoudre. 2.4.3 Les conflits Prenons l’exemple suivant : le développeur \\(D_1\\) et le développeur \\(D_2\\) on tous les 2 pullé la version v0.1 du code à l’instant \\(t\\) sur leur machine respective. Ils travaillent chacun indépendamment pour apporter des changements au code. Au moment de pusher ses changements, le développeur \\(D_2\\) reçoit un message d’erreur : “Sync Error. Please resolve all conflicted files, commit, then try syncing again.” Chaque fichier étant source de conflit a alors été automatiquement édité comme suit : &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD code dans votre version local ======= code en ligne &gt;&gt;&gt;&gt;&gt;&gt;&gt; remote Pour résoudre le conflit, il faut alors éditer chaque fichier un à un en choisissant s’il faut conserver la version locale ou bien celle en ligne, avant de pouvoir commiter à nouveau et enfin de pusher vos changements avec succès. A vous de jouer ! Modifiez le fichier README.Rmd de votre binome, puis commitez votre changement et pushez le. une fois que votre binôme a modifié votre README.Rmd, modifiez à votre tour le fichier à la même ligne, SANS puller les changements de votre binôme au préalable ! Commitez et essayez de pusher ces changements. Résolvez le conflit. 2.4.4 Fork L’action fork permet de créer une copie qui vous appartient à partir d’un code disponible. Ainsi le code original ne sera pas impacté par vos changements. Cela revient à créer une branche, et la séparer de l’arbre pour pouvoir en assumer la propriété. Cette action est principalement utile dans le cadre des pull requests. 2.4.5 Pull request Il s’agit du moyen le plus facile de proposer des changements dans un code dont vous n’êtes pas collaborateur. GitHub propose une interface graphique facilitant leur traitement. A vous de jouer ! Modifiez le README.Rmd de votre voisin qui n’est pas votre binôme après avoir forké son package. Proposez votre changement sous la forme d’une pull request. Acceptez la pull request sur le site de GitHub et faire le merge. 2.4.6 Issues Pour n’importe quel répertoire GitHub, vous pouvez poster un commentaire sous forme d’issue afin d’alerter les développeurs sur un éventuel bug, ou une question sur l’utilisation du package, ou encore demander une fonctionnalité supplémentaire… L’idéal est de proposer vous-même une pull request qui résout votre issue lorsque vous le pouvez (i.e. en avez les capacités et le temps). A vous de jouer ! Utilisez devtools::use_github_links() afin d’ajouter les 2 lignes suivantes au fichier DESCRIPTION de votre package URL: http://github.com/*prenom.nom*/mypkg BugReports: http://github.com/*prenom.nom*/mypkg/issues grâce à la fonction devtools::use_github_links() Visualisez les nouveau changements, puis commitez les. Créez une issue sur le projet de votre binome 2.5 Intégration continue À chaque changement, à chaque commit donc, il y a la possibilité d’introduire 1 (ou plusieurs) bugs qui vont empêcher le package de passer le CRAN check. Si l’on accumule trop de ces bugs, au moment de soumettre la nouvelle version, il peut y avoir beaucoup de corrections à apporter. C’est d’autant plus frustrant si le package passait le CRAN check auparavant… Les services d’intégration continue permettent de checker votre package automatiquement après chaque commit ! En cas d’échec, vous recevez un mail qui vous en informe. Un certain nombre de ces services proposent une offre limitée gratuite pour les projets open-source. Une autre raison d’utiliser l’intégration continue est qu’elle permet de tester votre package sur des infrastructures différentes de la votre (e.g. Windows, Ubuntu, Mac OS) et pour différentes versions de R (current, devel…) 2.5.1 Travis CI Travis est un service d’intégration continue (Continuous Integration), qui permet de checker votre package à chaque commit sous Ubuntu. La commande devtools::use_travis() initialise le fichier de configuration .travis.yml nécessaire. A vous de jouer ! Rendez vous sur le site https://travis-ci.org/ et créez vous un compte associé à votre GitHub en cliquant sur le bouton “SignIn with GitHub” en haut à droite. Activez votre repertoire mypkg sur Travis executez la commande devtools::use_travis() et commitez les changements et regardez ce qu’il se passe sur votre page Travis ajouter un joli badge à votre README.md grâce au code suivant (obtenu dans la console R) : [![Travis-CI Build Status](https://travis-ci.org/*prenomnom*/mypkgr.svg?branch=master)](https://travis-ci.org/*prenomnom*/mypkgr) et commitez les changements Travis permet également de tester votre package sous Mac OS (même si ce service est parfois moins stable). Ajoutez les lignes suivantes dans le fichier de configuration .travis.yml : r: - release - devel os: - linux - osx N’hésitez pas à aller visiter les pages de packages connus sur GitHub pour observer comment ils configurent leur fichier .travis.yml. 2.5.2 Appveyor Appveyor est l’analogue de Travis CI mais pour Windows. A vous de jouer ! Rendez vous sur le site https://ci.appveyor.com/ et créez vous un compte associé à votre GitHub en cliquant sur le bouton “GitHub” pour le Login Ajoutez votre repertoire mypkg sur Appveyor en cliquant sur “+ New project” en haut à gauche, puis en selectionnant GitHub et mypkg dans le menu. Executez la commande devtools::use_appveyor() et commitez les changements et regardez ce qu’il se passe sur votre page Appveyor ajouter un joli badge à votre README.md grâce au code suivant (obtenu dans la console R) : [![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/*prenomnom*/mypkgr?branch=master&amp;svg=true)](https://ci.appveyor.com/project/*prenomnom*/mypkgr) et commitez les changements 2.5.3 R-hub Le R consortium met à disposition le R-hub builder, et a pour ambition de bientôt proposer un service d’intégration continue spécialement dédié aux packages R. 2.6 Annexe 2.1 : couverture du code Le package covr propose une solution pour mesurer la couverture des tests unitaires associés à un package. La couverture de test détermine la proportion du code source qui est effectivement utilisée lors de l’exécution des tests unitaires. La mesure de la couverture du code renforce la fiabilité d’un code et donne confiance à ses utilisateurs potentiels. A vous de jouer ! Executez la commande devtools::use_appveyor(), ajouter un joli badge à votre README.md grâce au code suivant (obtenu dans la console R) : [![Coverage Status](https://img.shields.io/codecov/c/github/*prenomnom*/mypkgr/master.svg)](https://codecov.io/github/*prenomnom*/mypkgr?branch=master) Et ajouter au fichier .travis.yml: after_success: - Rscript -e &#39;covr::codecov()&#39; Commitez ces changements. Pour plus d’information n’hésitez pas à consulter la vignette de covr. "],
["mesurer-et-comparer-des-temps-dexecution.html", "3 Mesurer et comparer des temps d’exécution 3.1 Mesurer des temps d’exécution avec system.time() 3.2 Comparer des temps d’exécution avec microbenchmark()", " 3 Mesurer et comparer des temps d’exécution La première étape avant d’optimiser un code est de pouvoir mesurer son temps d’exécution, afin de pouvoir comparer les temps d’exécution entre différente implémentations. 3.1 Mesurer des temps d’exécution avec system.time() Pour mesure le temps d’exécution d’une commande R, on peut utiliser la fonction system.time() comme ceci : system.time(mvnpdf(x=matrix(rep(1.96, 2), nrow=2, ncol=1), Log=FALSE)) ## user system elapsed ## 0.002 0.000 0.002 Le problème qui apparaît sur cet exemple est que l’exécution est tellement rapide que system.time() affiche 0 (ou une valeur très proche). De plus, on voit qu’il y a une certaine variabilité quand on relance plusieurs fois la commande. Ainsi si on souhaite comparer notre code avec la fonction mvtnorm::dmvnorm(), on ne peut pas utiliser system.time() : system.time(mvtnorm::dmvnorm(rep(1.96, 2))) ## user system elapsed ## 0.004 0.000 0.004 On pourrait se dire qu’il faut augmenter la complexité de notre calcul, mais il y a mieux : utiliser le package microbenchmark ! 3.2 Comparer des temps d’exécution avec microbenchmark() Comme son nom l’indique, ce package permet justement de comparer des temps d’exécution même quand ceux-ci sont très faibles. De plus, la fonction microbenchmark() va répéter un certain nombre de fois l’exécution des commandes et donc va stabiliser le résultat. library(microbenchmark) mb &lt;- microbenchmark(mvtnorm::dmvnorm(rep(1.96, 2)), mvnpdf(x=matrix(rep(1.96,2)), Log=FALSE), times=1000L) mb ## Unit: microseconds ## expr min lq mean ## mvtnorm::dmvnorm(rep(1.96, 2)) 36.455 40.223 58.94536 ## mvnpdf(x = matrix(rep(1.96, 2)), Log = FALSE) 28.197 31.177 43.47682 ## median uq max neval ## 41.919 44.3010 13168.888 1000 ## 32.841 34.9535 8138.618 1000 Les deux fonctions mvnpdf() et dmnvorm() étant capables de prendre en entrée une matrice, on peut également comparer leurs comportements dans ce cas : n &lt;- 100 mb &lt;- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)), mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), times=100L) mb ## Unit: microseconds ## expr min ## mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) 43.001 ## mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 373.855 ## lq mean median uq max neval ## 47.4135 59.08513 53.1825 58.627 323.920 100 ## 387.7460 451.13240 401.5170 469.728 2043.951 100 Il s’est passé un quelque chose… Et on va diagnostiquer ce problème dans la suite. "],
["profiler-son-code.html", "4 Profiler son code 4.1 Comparaison avec une version plus habile de mnvpdf() 4.2 Comparaison avec une version optimisée dans R", " 4 Profiler son code On parle de profiling en anglais. Il s’agit de déterminer ce qui prend du temps dans un code. Le but étant une fois trouvé le bloc de code qui prend le plus de temps dans l’exécution d’optimiser uniquement cette brique. Pour obtenir un profiling du code ci-dessous, sélectionner les lignes de code d’intérêt et aller dans le menu “Profile” puis “Profile Selected Lines” (ou Ctrl+Alt+Shift P). n &lt;- 10e4 pdfval &lt;- mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE) OK, we get it ! Concaténer un vecteur au fur et à mesure dans une boucle n’est vraiment pas une bonne idée. 4.1 Comparaison avec une version plus habile de mnvpdf() Considérons une nouvelle version de mvnpdf(), appelée mvnpdfsmart(). Télécharger le fichier puis l’inclure dans le package. Profiler la commande suivante : n &lt;- 10e4 pdfval &lt;- mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE) On a effectivement résolu le problème et on apprend maintenant de manière plus fine ce qui prend du temps dans notre fonction. Pour confirmer que mvnpdfsmart() est effectivement bien plus rapide que mvnpdf() on peut re-faire une comparaison avec microbenchmark() : n &lt;- 1000 mb &lt;- microbenchmark(mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), times=100L) mb ## Unit: milliseconds ## expr min ## mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 4.272422 ## mvnpdfsmart(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 3.205948 ## lq mean median uq max neval ## 4.673746 5.609702 5.867266 6.013831 7.827174 100 ## 3.294764 3.556449 3.356483 3.436682 11.661349 100 Et on peut également voir si on devient compétitif avec dmvnorm() : n &lt;- 1000 mb &lt;- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)), mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), times=100L) mb ## Unit: microseconds ## expr min ## mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) 74.865 ## mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 4254.736 ## mvnpdfsmart(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 3159.560 ## lq mean median uq max neval ## 92.298 159.2387 136.3625 159.815 1198.118 100 ## 4622.349 5820.5562 5490.6405 5629.426 53676.639 100 ## 3247.691 3358.0277 3301.4995 3373.916 4616.023 100 Il y a encore du travail… 4.2 Comparaison avec une version optimisée dans R Boris est arrivée après plusieurs recherches et tests à une version optimisée avec les outils de R. Inclure la fonction mvnpdfoptim() dans le package, puis profiler cette fonction : n &lt;- 10e4 pdfval &lt;- mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE) Et un petit microbenchmark() : n &lt;- 1000 mb &lt;- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)), mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), times=100L) mb ## Unit: microseconds ## expr min ## mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) 74.003 ## mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 4248.901 ## mvnpdfsmart(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 3137.125 ## mvnpdfoptim(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 1246.205 ## lq mean median uq max neval ## 96.2295 130.9313 127.354 162.921 267.537 100 ## 4461.3940 5906.1418 5570.766 5883.340 54393.622 100 ## 3271.6400 3495.1396 3336.419 3471.472 5297.640 100 ## 1320.1805 1480.8744 1345.163 1409.999 8731.673 100 Pour finir on peut profiler la fonction dmvnorm() : n &lt;- 10e5 pdfval &lt;- mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) "],
["rcpp-ou-comment-integrer-facilement-du-code-cdans-un-package-r.html", "5 Rcpp ou comment intégrer facilement du code C++dans un package R 5.1 Première fonction en Rcpp 5.2 Optimisation grâce à C++ 5.3 Annexe 6.1 : l’optimisation prématurée n’est pas une bonne idée", " 5 Rcpp ou comment intégrer facilement du code C++dans un package R Rcpp (R-C-Plus-Plus) est un package qui facilite l’interface entre C++ et R. R est un langage interprété, ce qui facilite un certain nombre de choses (notamment nous donne accès à la console dans laquelle on peut évaluer du code à la volée). Néanmoins, cette facilité d’utilisation se compense entre autre par des temps de calcul supérieurs à ceux de langages de plus bas niveau, tels que C, Fortran et C++ (mais qui nécessitent eux une compilation). On dirigera le lecteur curieux vers le livre en ligne Rcpp for everyone de Masaki E. Tsuda, qui constitue une ressource très complète pour comprendre l’utilisation de Rcpp en plus de l’introduction que l’on peut trouver dans le livre Advanced R d’Hadley Wickham. 5.1 Première fonction en Rcpp A vous de jouer ! Afin de rendre votre package prêt pour l’utilisation avec Rcpp, commencez par executer la commande suivante : devtools::use_rcpp() Constatez les changements apportés il faut également ajouter les 2 commentaires roxygen suivants dans la page d’aide du package dans son ensemble : #&#39; @useDynLib mypkgr #&#39; @importFrom Rcpp sourceCpp, .registration = TRUE NULL Nous allons maintenant créer une première fonction en Rcpp permettant d’inverser une matrice. Pour cela, nous allons nous appuyer sur la library C++ Armadillo. Il s’agit d’une library d’algèbre linéaire moderne et simple, hautement optimisée, et interfacée avec R via le package RcppArmadillo. C++ n’est pas un langage très différent de R. Les principales différences qui nous concernent : C++est très efficaces pour le boucles for (y compris les boucles for emboîtées). Attention : il y a souvent un sens qui est plus rapide que l’autre (ceci est dû à la manière dont C++ attribue et parcours la mémoire). Chaque commande doit se terminer par un point virgule ‘;’ C++est un langage typé : il faut déclarer le type de chaque variable avant de pouvoir l’utiliser. A vous de jouer ! Créez un nouveau fichier C++ depuis RStudio (via le menu File &gt; New File &gt; C++ File), et enregistrez le dans le dossier src. Prenez le temps de le lire et essayez de comprendre chaque ligne. Compilez et chargez votre package (via le bouton “Install and Restart”) et essayez d’utiliser la fonction timesTwo() depuis la console. Installez le package RcppArmadillo, et n’oubliez pas de faire les ajouts nécessaires dans DESCRIPTION (cf. Rcpp précédement - vous pouvez expérimentez avec la fonction RcppArmadillo::RcppArmadillo.package.skeleton() qui a le désavantage de créer beaucoup de fichiers inutiles) À l’aide de la documentation des packages Rcpp et RcppArmadillo de celle de la library Armadillo, tentez d’écrire une courte fonction invC en C++ calculant l’inverse d’une matrice. Lorsque vous avez réussi à compiler votre fonction invC et qu’elle est accèssible depuis R créer une fonction mvnpdf_invC() à partir de l’implémentation de mvnpdfsmart en remplaçant uniquement les calculs d’inverse matriciel par un appel à invC. Evaluer le gain en performance de cette nouvelle implémentation mvnpdf_invC n &lt;- 1000 mb &lt;- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)), mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdf_invC(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), times=100L) mb ## Unit: microseconds ## expr min ## mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) 78.486 ## mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 4322.436 ## mvnpdfsmart(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 3239.839 ## mvnpdfoptim(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 1237.231 ## mvnpdf_invC(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) 1245.840 ## lq mean median uq max neval ## 102.029 134.0075 133.6725 151.5305 240.470 100 ## 4435.944 4878.7963 4525.0015 4833.4670 8740.109 100 ## 3364.983 3802.8192 3483.3955 3771.5940 8706.301 100 ## 1349.568 1538.3178 1430.6560 1505.1915 3582.589 100 ## 1320.345 1847.9877 1373.0855 1472.4730 37461.285 100 profvis::profvis(mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = 1000), Log=FALSE)) profvis::profvis(mvnpdfoptim(x=matrix(1.96, nrow = 100, ncol = 1000), Log=FALSE)) 5.2 Optimisation grâce à C++ En règle générale, on ne gagne pas beaucoup en temps de calcul en remplaçant une fonction R optimisée par une fonction en C++. En effet, la plupart des fonctions de base de R s’appuie en réalité déjà sur des routines C ou Fortran bien optimisée. Le gain se limite alors simplement à la suppression des vérifications des arguments et de la gestion des différents types. A vous de jouer ! À partir de mvnpdfsmart, proposez une implémentation completement en C++ du calcul de densité de la loi Normale multivariée mvnpdfC(). Evaluer le gain en performance de cette nouvelle implémentation mvnpdf_invC Vous pouvez télécharger notre proposition de mvnpdfC.cpp ici. n &lt;- 1000 mb &lt;- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)), mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdf_invC(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfC(x=matrix(1.96, nrow = 2, ncol = n), mean = rep(0, 2), varcovM = diag(2), Log=FALSE), times=100L) mb ## Unit: microseconds ## expr ## mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) ## mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) ## mvnpdfsmart(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) ## mvnpdfoptim(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) ## mvnpdf_invC(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) ## mvnpdfC(x = matrix(1.96, nrow = 2, ncol = n), mean = rep(0, 2), varcovM = diag(2), Log = FALSE) ## min lq mean median uq max neval ## 75.418 105.9575 132.83411 133.8985 150.0225 301.426 100 ## 4287.315 4441.7190 5328.34447 4534.6065 4863.4660 56688.565 100 ## 3149.672 3316.1710 3629.29124 3405.9575 3652.0720 5128.620 100 ## 1223.180 1310.7840 1442.68781 1351.8000 1427.7340 4120.596 100 ## 1233.084 1297.9170 1505.50775 1367.3990 1501.8985 4515.643 100 ## 46.680 53.9065 65.38855 61.6155 66.9430 208.604 100 À noter que vous pouvez utiliser des fonctions Rcpp en dehors de l’architecture d’un package grâce à la fonction Rcpp::sourceCpp(). Mais comme nous avons qu’il est préférable de gérer tous ces code sous la forme de package, il est peu probable que vous en ayez besoin ! 5.3 Annexe 6.1 : l’optimisation prématurée n’est pas une bonne idée Chambers, Software for Data Analysis: Programming with R, Springer, 2008 : Including additional C code is a serious step, with some added dangers and often a substantial amount of programming and debugging required. You should have a good reason. "],
["parallelisation-du-code-r.html", "6 Parallélisation du code R 6.1 Introduction à l’execution parallèle sous R 6.2 Première fonction parallèle en R 6.3 Parallélisation efficace 6.4 Parallélisation dans notre exemple fil rouge 6.5 Conclusion", " 6 Parallélisation du code R 6.1 Introduction à l’execution parallèle sous R En dehors de l’optimisation du code et des algorithmes, une autre façon d’obtenir un code performant est de tirer profit des architectures parallèles des ordinateurs modernes. Il s’agit alors de paralléliser son code afin de faire des opérations simultanées sur des parties distinctes d’un même problèmes, en utilisant différent cœurs de calcul. On ne réduit pas le temps de calcul total nécessaire, mais l’ensemble des opérations s’exécute plus rapidement. Il existe un nombre non négligeable d’algorithmes qui sont d’un “parallélisme embarrassant”, c’est-à-dire dont les calculs peuvent se décomposer en plusieurs sous-calculs indépendants. En statistique, il est ainsi souvent facile et direct de paralléliser selon les différentes observations ou selon les différentes dimensions. Typiquement, il s’agit d’opérations que l’on peut écrire sous la forme de boucle dont les opérations sont indépendantes d’une itération de la boucle à l’autre. Les opérations nécessaires pour l’établissement d’un code parallèle sont les suivantes : Démarrer \\(m\\) processus “travailleurs” (i.e. cœurs de calcul) et les initialiser Envoyer les fonctions et données nécessaires pour chaque tache aux travailleurs Séparer les taches en \\(m\\) opérations d’envergure similaire et les envoyer aux travailleurs Attendre que tous les travailleurs aient terminer leurs calculs et obtenir leurs résultats Rassembler les résultats des différents travailleurs Arrêter les processus travailleurs Selon les plateformes, plusieurs protocoles de communications sont disponibles entre les cœurs. Sous les systèmes UNIX, le protocole Fork est le plus utilisé, mais il n’est pas disponible sous Windows où on utilise préférentiellement le protocole PSOCK. Enfin, pour les architecture de calcul distribuée où les cœurs ne se trouvent pas nécessairement sur le même processeur physique, on utilise généralement le protocole MPI. L’avantage des packages parallel et doParallel est que la même syntaxe permettra d’exécuter du code en parallèle quelque soit le protocole de communication retenu. Il existe un nombre important de packages et d’initiatives permettant de faire du calcul en R. Depuis R 2.14.0, le package parallel est inclus directement dans R et permet de démarrer et d’arrêter un “cluster” de plusieurs processus travailleur (étape 1). En plus du package parallel, on va donc utiliser le package doParallel qui permet de gérer les processus travailleurs et la communication (étapes 1) et l’articulation avec le package foreachqui permet lui de gérer le dialogue avec les travailleurs (envois, réception et rassemblement des résultats - étapes 2, 3, 4 et 5). 6.2 Première fonction parallèle en R À vous de jouer ! On va commencer par écrire une fonction simple qui calcule le logarithme \\(n\\) nombres: Déterminez combien de coeurs sont disponibles sur votre marchine grâce à la fonction parallel::detectCores(). À l’aide de la fonction parallel::makeCluster(), créez un cluster de coeur (en prenant garde à laisser un coeur disponible pour traiter les autres processus) et déclarer ce cluser via la fonction doParallel::registerDoParallel(). À l’aide de l’opérateur %dopar% du package foreach, calculez le log des \\(n\\) nombres en parallèle et concaténer les résultats dans un vecteur. Fermez enfin les connections de votre cluster via la fonction parallel::stopCluster(cl). Comparez le temps d’éxecution avec celui d’une fonction séquentielle sur les 100 premiers entiers, grâce à la commande : microbenchmark(log_par(1:100), log_seq(1:100), times=10) library(microbenchmark) library(parallel) library(foreach) library(doParallel) log_par &lt;- function(x){ Ncpus &lt;- parallel::detectCores() - 1 cl &lt;- parallel::makeCluster(Ncpus) doParallel::registerDoParallel(cl) res &lt;- foreach(i=1:length(x), .combine=&#39;c&#39;) %dopar% { log(x[i]) } parallel::stopCluster(cl) return(res) } log_seq &lt;- function(x){ # res &lt;- numeric(length(x)) # # for(i in 1:length(x)){ # res[i] &lt;- log(x[i]) # } # # return(res) return(log(x)) } mb &lt;- microbenchmark(log_par(1:100), log_seq(1:100), times=50) La version parallèle tourne beaucoup plus lentement… Car en fait, si les tâches individuelles sont trop rapides, R va passer plus de temps à communiquer avec les cœurs, qu’à faire les calculs effectifs. Il faut qu’une itération de la boucle soit relativement longue pour que le calcul parallèle apporte un gain en temps de calcul ! En augmentant \\(n\\), on observe une réduction de la différence entre les 2 implémentations (le temps de calcul en parallèle augmente très lentement comparé à l’augmentation de celui de la fonction séquentielle). NB : les itérateurs d’itertools sont très performants mais ne peuvent servir que lorsque le code à l’intérieur du foreach est vectorisé (il est toujours possible de vectoriser le code à l’intérieur, par exemple avec une fonction de type apply). Ils minimisent le nombre de communication entre les coeurs. 6.3 Parallélisation efficace On va maintenant se pencher sur un autre cas d’utilisation. Imaginons que l’on ait un grand tableau de données de taille comportant 10 observations pour 100 000 variables (e.g. des mesures de génomique), et que l’on veuille calculer la médiane pour chacune de ces variables. x &lt;- matrix(rnorm(1e6), nrow=10) dim(x) ## [1] 10 100000 Pour un utilisateur averti de R, une telle opération se programme facilement à l’aide de la fonction apply : colmedian_apply &lt;- function(x){ return(apply(x, 2, median)) } system.time(colmedian_apply(x)) ## user system elapsed ## 2.612 0.000 2.629 En réalité, une boucle for n’est pas plus lente à condition d’être bien programmée : colmedian_for &lt;- function(x){ ans &lt;- rep(0, ncol(x)) for (i in 1:ncol(x)) { ans[i] &lt;- median(x[,i]) } } system.time(colmedian_for(x)) ## user system elapsed ## 2.464 0.000 2.464 microbenchmark(colmedian_apply(x), colmedian_for(x), times=20) ## Unit: seconds ## expr min lq mean median uq max ## colmedian_apply(x) 2.57899 2.644573 2.746615 2.705471 2.777248 3.319525 ## colmedian_for(x) 2.39265 2.485342 2.598944 2.582138 2.683714 2.934028 ## neval ## 20 ## 20 À vous de jouer ! Essayons d’améliorer encore ce temps de calcul en parallélisant : 1 . Parallélisez le calcul de la médiane de chacune des 100 000 variables. Observe-t-on un gain en temps de calcul ? Proposez une implémentation alternative grâce à la fonction itertools::isplitIndices() qui permet de séparer vos données (les \\(n\\) nombres) en autant de groupes que vous avez de coeurs. Comparez à nouveau les temps de calcul. colmedian_par &lt;- function(x){ Ncpus &lt;- parallel::detectCores() - 1 cl &lt;- parallel::makeCluster(Ncpus) doParallel::registerDoParallel(cl) res &lt;- foreach::foreach(i=1:ncol(x), .combine=&#39;c&#39;)%dopar%{ return(median(x[,i])) } parallel::stopCluster(cl) return(res) } system.time(colmedian_par(x)) ## user system elapsed ## 22.395 1.321 24.778 library(itertools) colmedian_parIter &lt;- function(x){ Ncpus &lt;- parallel::detectCores() - 1 cl &lt;- parallel::makeCluster(Ncpus) doParallel::registerDoParallel(cl) iter &lt;- itertools::isplitIndices(n=ncol(x), chunks = Ncpus) res &lt;- foreach::foreach(i=iter, .combine=&#39;c&#39;)%dopar%{ return(apply(x[, i], 2, median)) } parallel::stopCluster(cl) return(res) } system.time(colmedian_parIter(x)) ## user system elapsed ## 0.036 0.026 1.850 colmedian_parIterFor &lt;- function(x){ Ncpus &lt;- parallel::detectCores() - 1 cl &lt;- parallel::makeCluster(Ncpus) doParallel::registerDoParallel(cl) iter &lt;- itertools::isplitIndices(n=ncol(x), chunks = Ncpus) res &lt;- foreach(i=iter, .combine=&#39;c&#39;) %dopar% { xtemp &lt;- x[,i] ans &lt;- rep(0, ncol(xtemp)) for (j in 1:ncol(xtemp)) { ans[j] &lt;- median(xtemp[,j]) } return(ans) } parallel::stopCluster(cl) return(res) } system.time(colmedian_parIterFor(x)) ## user system elapsed ## 0.065 0.023 1.785 mb &lt;- microbenchmark(colmedian_apply(x), colmedian_for(x), colmedian_parIter(x), colmedian_parIterFor(x), times=20) mb ## Unit: seconds ## expr min lq mean median uq ## colmedian_apply(x) 3.261284 3.335229 3.397566 3.391059 3.451899 ## colmedian_for(x) 3.012508 3.084203 3.209585 3.143014 3.284979 ## colmedian_parIter(x) 1.830079 1.918276 1.993144 1.966710 2.017255 ## colmedian_parIterFor(x) 1.744435 1.771207 1.863021 1.833185 1.892802 ## max neval ## 3.596851 20 ## 3.615660 20 ## 2.460515 20 ## 2.267777 20 Le package itertools permet de séparer facilement des données ou des taches (étape 3) tout en minimisant les communiquations avec les différents travailleurs. Il s’appuie sur une implémentation des itérateurs en R. Son utilisation nécessite néanmoins de vectoriser le code à l’intérieur du foreach. Expérimentez avec le petit code ci-dessous : myiter &lt;- itertools::isplitIndices(n=30, chunks = 3) # Une première fois iterators::nextElem(myiter) ## [1] 1 2 3 4 5 6 7 8 9 10 # Une deuxième fois... Oh ?! iterators::nextElem(myiter) ## [1] 11 12 13 14 15 16 17 18 19 20 # Encore ! iterators::nextElem(myiter) ## [1] 21 22 23 24 25 26 27 28 29 30 # Encore ? iterators::nextElem(myiter) ## Error: StopIteration 6.4 Parallélisation dans notre exemple fil rouge À vous de jouer ! 1 . À partir de la fonction mvnpdfoptim() et/ou mvnpdfsmart(), proposez une implémentation parallélisant les calculs sur les observations (colonnes de \\(x\\)) Comparez les temps de calcul sur 10 000 observations n &lt;- 10000 mb &lt;- microbenchmark::microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)), mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), mvnpdfoptim_par(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE), times=10L) mb ## Unit: microseconds ## expr ## mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)) ## mvnpdfoptim(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) ## mvnpdfoptim_par(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE) ## min lq mean median uq max neval ## 618.28 714.604 886.9507 882.869 1061.721 1188.519 10 ## 17761.52 17945.602 20565.9590 19587.459 20868.068 29376.875 10 ## 583349.14 613340.267 676758.4185 662754.130 710727.523 805168.680 10 6.5 Conclusion La parallélisation permet de gagner du temps, mais il faut d’abord bien optimiser son code. Quand on parallélise un code, le gain sur la durée d’exécution dépend avant tout du ratio entre le temps de communication et le temps de calcul effectif pour chaque tache. "],
["miscelanees.html", "7 Miscélanées 7.1 Debugging avec browser() 7.2 attach 7.3 gestion mémoire 7.4 copies et variables locales/globales dans les fonctions 7.5 naming 7.6 gpplot2", " 7 Miscélanées 7.1 Debugging avec browser() 7.2 attach 7.3 gestion mémoire 7.4 copies et variables locales/globales dans les fonctions 7.5 naming 7.6 gpplot2 "],
["take-home-message.html", "8 Take Home message", " 8 Take Home message FAITES DES PACKAGES utilisez git, au moins pour vous en local si besoin (i.e. après optimisation du code R lui même), n’ayez pas peur de vous tourner vers Rcpp et/ou la parallélisation de votre code "],
["references.html", "Références", " Références Les livres en ligne d’Hadley Wickham sont vraiment excellents et contiennent beaucoup de compléments par rapport à tous ce qu’on a traité dans cette formation. le site sur la construction de package R packages. le site Advanced R pour tout ce qui est optimisation, Rcpp, calcul parallèle. le site R for Data Science est également très complet et comprend des chapitres sur la gestion des structures de données dans R, mais aussi la modélisation et des éléments sur les graphiques et Rmarkdown. le livre en ligne Rcpp for everyone de Masaki E. Tsuda est également très bien fait "],
["references-1.html", "References", " References "]
]
