--- 
title: 'Advanced `r fontawesome::fa("r-project")` course'
subtitle: '*Tools for software development and performance*'
author: "***Robin Genuer*** [`r emoji::emoji('globe_with_meridians')`](https://robin.genuer.fr/) & ***Boris Hejblum*** [`r emoji::emoji('globe_with_meridians')`](https://borishejblum.science/)"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "Tools for software development and performance"
---

# Course syllabus {-}

The main goal of this course is to give you tools that ease (high-performing and effcient) code development with `r fontawesome::fa("r-project")`. The *performance* side will come as a second part, and the initial tools introduced are also very useful in situations that do not require
important computation times.

We will focus the presentation of these development tools on the notion of **package**. *You are already familiar with this notion*, as you have already
already installed packages from the CRAN for example ! You also know that it is the most standard way in `r fontawesome::fa("r-project")` to distribuute code and make it available.
We will show you that the package is also an excellent tool for developing code.


We will follow the outline below:

 1. Build an `r fontawesome::fa("r-project")` package as a useful tool for code development

 2. Leverage `git` for **tracking** changes, and `GitHub` for **sharing** code, **collaborative** development, automating tests in a package and broadcast a companion website

 3. **Measure** computation time

 4. **Profile** the code

 5. Use `Rcpp` to **optimize** what needs to be optimized

 6. **Parallelize** the code easily


## Required tools {-}

To take this course, you will need to have the following softwares installed:

  - the latest version of `r fontawesome::fa("r-project")` (https://cloud.r-project.org/)

  - the latest version of `RStudio` (https://posit.co/download/rstudio-desktop/#download)

  - a *C++ compiler* (such as `gcc` or `clang` - native on UNIX systems, 
	for Windows users we recommend installing 
	[Rtools](https://cran.r-project.org/bin/windows/Rtools/), for 
	Mac users it may be necessary to install the macOS tool chain as detailed [here](https://mac.r-project.org/tools/)

  - the following `r fontawesome::fa("r-project")` packages: `devtools`, `future.apply`, `itertools`, `microbenchmark`, `mvtnorm`, `profvis`, `Rcpp`, `RcppArmadillo`, `roxygen2`, `testthat`, `usethis`

  - the software [*git*](https://git-scm.com/) which can be installed following instructions from [*Happy Git With R* by Jenny Brian](https://happygitwithr.com/install-git.html)
  
In addition, you will need an active internet connection (e.g. through *eduroam*)



## Prerequisites {-}

To be able to follow along this training, you must be comfortable with the following concepts: 

  - programing with `r fontawesome::fa("r-project")` within the `RStudio` IDE
  - writing functions in `r fontawesome::fa("r-project")`
  - control structures, particularly *for* loops
  - the calculation of the density for a multivariate Gaussian distribution


<!--chapter:end:index.Rmd-->


# Building an `r fontawesome::fa("r-project")` package

Here we present how to efficiently create and build a package using *RStudio* IDE, and the `devtools` and `usethis` packages.

More details are provided in the reference material on this subject: the book [*R packages*](https://r-pkgs.org/)[^1] by Hadley Wickham & Jennifer Bryan, freely available online.

[^1]: *R Packages* (2^nd^ Edition) by Hadley Wickham, Jennifer Bryan. O'Reilly, 2023. ISBN: 9781098134945. [https://r-pkgs.org/](https://r-pkgs.org/)



## Initializing a package

A simple way, built into *RStudio*, to **initialize a package** is to follow those steps:

> `r emoji::emoji("point_right")` **Your turn** (already)!
>
>  1. create a new project (top left `File` drop down menu in *RStudio*)
>  
>  2. choose "*New Directory*"
>  
>  3. choose "*R package using devtools*" (if it is not available, choose "*R package*", the difference being that with "*R package*" you will have to delete unnecessary files that are automatically created but not useful)
>  
>  4. give a name to your package, for example `mypkgr`.
  
  
From that, we get the **minimal structure for an** `r fontawesome::fa("r-project")` package, namely:

  - a **DESCRIPTION** file whose `Title`, `Version`, `Authors@R` and `Description` are to be edited (other parts can be edited or even added automatically, see below)
  
  - a **NAMESPACE** file which will be **later** edited automatically (so hands off for now)
  
  - a folder **R/** in which we will add `.R` script files
  
  
`devtools` also adds three ***optional* files**:

  - **.gitignore**, relative to `git`, a version control tool that we will see in detail in the following section on `git` & *GitHub*
  
  - **mypkgr.Rproj** which is a specific file of *RStudio*, and allows to define the characteristics and preferences of the project we just created
  
  - **.Rbuildignore** which allows to ignore some files when we build the package down the road (for example, the `mypkgr.Rproj` file should not be included in the package)
  


## Adding a function: common theme example

We first invite you to code the following function, which we will use throughout the course:

We want to compute the value of the density of a multivariate normal distribution on $\mathbb{R}^p$ at $n$ points. Our function must be applicable for any multivariate normal distribution (i.e. any mean vector $\boldsymbol\mu$ in $\mathbb{R}^p$ and variance-covariance matrix $\boldsymbol\Sigma$ of order $p$), and we wish to compute all the values of the density evaluated at the $n$ points $\mathbf{x}$ in a single call of the function.

As a reminder, the density function for a multivariateGaussian distribution is:
$$\displaystyle (2\pi )^{-p/2}\det({\boldsymbol {\Sigma }})^{-1/2}\,\exp \left(-{\frac {1}{2}}(\mathbf {x} -{\boldsymbol {\mu }})^{\mathsf {T}}{\boldsymbol {\Sigma }}^{-1}(\mathbf {x} -{\boldsymbol {\mu }})\right)$$

So you need to create a function `mvnpdf()` in a file named `mvnpdf.R` in the `R/` folder of your package, which :

  - takes as arguments:
    
      - `x` a matrix, with $n$ columns (the observations) and $p$ rows
      
      - `mean` a vector of means
      
      - `varcovM` a variance-covariance matrix
      
      - `Log` a logical parameter, with default value to `TRUE`.
      
  - returns a list containing the matrix `x`, and a vector of length $n$ of the multivariate normal distribution density values at those points.

> `r emoji::emoji("point_right")` ***Your turn !***  



Here is a function proposal that you can download [here](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfRAW.R). `r emoji::emoji("warning")` *WARNING !* if you click too quickly on this link, it will invalidate your participation in the class !

For advice on writing code, see the [R code](https://r-pkgs.org/code.html) section from Wickham & Bryan *R packages* (2023) by Wickham & Bryan[^1].



## Documenting a function

It is important to properly document your code. Every project has at least two developers:

  - yourself,
    
  - and yourself in 6 months.
  
For the sake of your future self, do yourself a favor and take the time to document your code !

We strongly advise you to use the `roxygen2` package to document your packages. The main advantage being to have the help of a function in the same file as the code defining this function.

> `r emoji::emoji("point_right")` ***Your turn !***  
>
  1. Start by inserting the skeleton of the helper with "Insert Roxygen
  Skeleton" located in the "Code" menu or the *Magic Wand* sub-menu in
  the script window.
>  
  2. Complete the documentation by filling in:
>
>      - the title of the function (first line)
>      
>      - the description of what the function does (second paragraph)
>      
>      - if you fill in a third paragraph, this part will go in the "Details" section of the help page
 >     
 >     - the meaning of the parameters
 >     
 >     - the output, after the `@return` tag
 >     
  3. Generate the documentation using "Document" in the "More" menu of the "Build" tab (or alternatively run `devtools::document()` or use `Ctrl+Shift+D`). The effect of this command is multiple:
>
>      - a `man` folder is created and inside it, a `mvnpdf.Rd` file contains the help information about the function
>      
>      - the `NAMESPACE` file is modified
      
**In case of problems OR out of curiosity but only once you are done**, you can have a look at this [proposal](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfRox.R).
      
For more details on package documentation and `roxygen2` tags, see the [Object documentation](https://r-pkgs.org/man.html) section from Wickham & Bryan *R packages* (2023)

Let us finish by mentioning a function from the `usethis` package which initializes a home help page for the whole package:

```{r, eval=FALSE}
usethis::use_package_doc()
```

The generated help page will then be accessible, once the package is installed, with the following command:

```{r, eval=FALSE}
?mypkgr
```


## Interactively test the package

To test the package, you have to load it in `r fontawesome::fa("r-project")` using "Load All" (or Ctrl+Shift+L) in the "More" menu from the "Build" tab, or alternatively `devtools::load_all()`).

You can then use your package directly in `r fontawesome::fa("r-project")`: look at the function help page with `?mvnpdf` and for example execute the commands given in the example section of this help page.

```{r, eval=FALSE}
?mvndpf
```
 
During code development, you can thus:

  - Add/Modify the `r fontawesome::fa("r-project")` code
  
  - Re-load the package `Ctrl+Shift+L`
  
  - Experiment with it in the console
  
  - And so on...



## *Automatically* test your package

To initialize automatic testing capabilities in your package, execute the following command:

```{r, eval=FALSE}
usethis::use_testthat()
```

This command creates a `tests` folder which includes a `testthat.R` file -- not to be modified -- and a `testthat/` folder in which we will add our automated tests. This tool is based on the theory of `unit tests`.

For example, here is the content of a file, containing two tests, that should be named `test-mvnpdf.R` and be put into the `testthat` folder (instead of doing this by hand, you can simply use the helper function `usethis::use_test()` that will create the file at the right place for you):

```{r, eval=FALSE}
test_that("correct result for univariate gaussian", {
  expect_equal(mvnpdf(x=matrix(1.96), Log=FALSE)$y, dnorm(1.96))
  expect_equal(mvnpdf(x=matrix(c(1.96, -0.5), ncol = 2), Log=FALSE)$y,
               dnorm(c(1.96, -0.5)))
})

test_that("correct results for bivariate gaussian", {
  expect_equal(mvnpdf(x=matrix(rep(1.96,2), nrow=2, ncol=1), Log=FALSE)$y,
               mvtnorm::dmvnorm(rep(1.96, 2)))
})
```


To execute these tests, you can click on "Test package" (`Ctrl+Shift+T`) in the "More" menu from the "Build" tab, or run `devtools::test()`

The advantage of these automatic tests is that they will be run every time you *check* the package (see just below).

A good practice is to add a unit test each time a bug is identified and fixed,
so that we can immediately identify and prevent the same error from happening again in the future.



## *Checking* your package

Running a *check* means ensuring that everything in your package is correct and will work as expected, and that it can be installed properly under various OS. "Passing `R CMD CHECK`" is **mandatory** for successfully uploading your package on CRAN.

To perform `R CMD CHECK` on your package, you can click on "Check" (`Ctrl+Shift+E`) from the "Build" tab, or run `devtools::check()`.

During the *check*, the automated unit tests that we have developed previously are executed. This is the advantage of having written these tests, we don't need to worry about it, simply react and adjust the code when errors are returned and flagged.


## Install your package

For the moment, the package exists only in the environment associated with the *RStudio* project we have created. To be able to use it anywhere (on your computer) in `r fontawesome::fa("r-project")` in a general way, you have to install it (like a CRAN package for example).

To do this, click on "Install" (`Ctrl+Shift+B`) from the "Build" tab, or alternatively you can run `devtools::install()`.

And finally, you can configure *RStudio*'s behavior so that at the time of installation, it simultaneously documents the package: go to the "*More*" menu from the "*Build*" tab, then "*Configure Build Tools...*". Then click on "*Configure*" next to "*Generate documentation with Roxygen*", and check the box "*Install and Restart*".




## Appendix 1.1: add an `S3 method` {-}

In most packages, we often have to implement so called `S3 methods` so that, from a result object `res`, one can run `print(res)`, `summary(res)`, `plot(res)`, ...

Here is an example of a `plot()` method that we can add to our package:

```{r, eval=FALSE}
#' Plot of the mvnpdf function
#'
#' @param x an object of class \code{mvnpdf} resulting from a call of
#' \code{mnvpdf()} function.
#' @param ... graphical parameters passed to \code{plot()} function.
#'
#' @return Nothing is returned, only a plot is given.
#' @export
#'
#' @examples
#' pdfvalues <- mvnpdf(x=matrix(seq(-3, 3, by = 0.1), nrow = 1), Log=FALSE)
#' plot(pdfvalues)
plot.mvnpdf <- function(x, ...) {
  plot(x$x, x$y, type = "l", ...)
}
```

`r emoji::emoji("warning")` *WARNING !* In order for this *S3 method* to do what we want it to do when we apply it to the result of our function `mvnpdf()`, we have to declare that `mvnpdf()` returns a result of class `mvnpdf`.

Test this function, by executing the example.\
*Don't forget to re-install the package ("Install" or `Ctrl+Shift+B`)*.

Look at the contents of the `man` folder and the changes that have been made to `NAMESPACE`.

*Here is a proposed solution*: the [file](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdf.R) contains the complete code of the `mvnpdf()` function and the associated `plot()` method.


## Appendix 1.2: submit one's package on [CRAN](https://cran.r-project.org/web/packages/available_packages_by_name.html) {-}

Run the two following commands: `devtools::check()` followed `devtools::submit_cran()`.
For more details, see Wickham & Bryan's recommended pipeline in their book [*R packages*](https://r-pkgs.org/release.html#release-process)

<!--chapter:end:02-build_package.Rmd-->


# Version control with `git` and *GitHub* 

We are interested here in the solutions offered by *RStudio* and *GitHub* for hosting and version control of projects. This allows to monitor changes history, to help collaborative development and to facilitate continuous integration.

## Principles of version control

The principle of version control is to record the successive changes made to files (especially `.R` files in our case).

*RStudio* offers 2 integrated solutions for version control:

  - `git`
  
  - `svn` ("subversion")




### `git`

`git` is a version control software (i.e. a tool that will record the history of successive changes to your code and allow you to share these changes with other people). `git` is a command line program, and it is not necessarily very intuitive to use. 

`git` works as follows: on a remote server (e.g. in the cloud), an **updated** version of the code is available. At any time it is possible to access this version of the code online. Each contributor can download this last **updated** version (in an action called *pull*), before editing it locally. Once changes are made locally, the contributor can then update the online version of the code, so that his changes become available to everyone (in an action called *push*).

**NB:** `git` was designed for lightweight files (such as text files) and is far from being optimized for heavy and/or compressed files (e.g. `.RData` files).

![Artwork CC-BY Allison Horst](AdvancedRcourse_dev_perf_files/git_workflow.png){width=100%}

### `subversion`

`subversion` is the other solution available in *RStudio*. It works in a similar way to git, but with less features that we won't detail here (the major difference is that all contributors work simultaneously on the same version of the code).




## Use `git` locally within *RStudio*

> `r emoji::emoji("point_right")` ***Your turn !***  
> 
  1. Start by enabling `git` from the "Git/SVN" tab of "Project Options" located in the "Tools" menu and follow the instructions. You can also use `usethis::use_git()`.
>  
  2. From the "Git" tab that now appears next to the "Build" tab, 
  register the current state of your package by making your first commit:
 >     
      - 2a. Select the files to track (do not select the `.Rproj` file)
 >     
      - 2b. write an informative message (for your collaborators -- this includes your future self)
 >     
      - 2c. click on "Commit"
>     
  3. Add a "*.Rproj" line to the ".gitignore" file and make a new commit
>  
  4. Visualize the changes and their history using the visualization tools 
  "Diff" and "History" tools accessible from the "Git" tab
  
  
![Artwork CC-BY Allison Horst](AdvancedRcourse_dev_perf_files/github_fall.png){width=100%}
  

### Good *commit* practices

Ideally, each commit should solve only one problem. It should fix it in its entirety (be **complete**), and contain only changes related to that very problem (be **minimal**). It is especially useful to write **informative** commit messages (be kind and help your collaborators, which includes your **future self**). You should also be concise, and describe the reasons for the changes rather than the the changes themselves (visible in the *Diff*).  
**NB:** it is sometimes difficult to follow these guidelines to the letter, and they are merely an ideal guide. They certainly should not prevent you from should from regularly making *commits*. 

On the other hand, the temptation to have a *"clean" and tidy* change-history is natural, but it is a source of unnecessary problems. It contradicts the traceability goal of version control. Since code development is generally a complex, messy, and non-linear intellectual process, it is normal that the recording of changes reflects this path. In practice, your future self will be the first user of your change history, so the priority is to make it easier for you in the future when solving bugs or extending functionality.


![Artwork CC-BY Allison Horst](AdvancedRcourse_dev_perf_files/github_wickham_bryan_git_quote.png){width=100%}

## *GitHub*

[*GitHub*](https://github.com/) is a website offering an online code hosting solution, and is based on `git`. There are many alternative websites and services ([*GitLab*](https://about.gitlab.com/), [*Bitbucket*](https://bitbucket.org/), ...) allowing to host code and also based on `git`. *GitHub* is very popular in the `r fontawesome::fa("r-project")` community, and is relatively easy to use, even for a novice user.

**Advantages** of using *GitHub*:
 
  - a simple and user-friendly graphical interface to track the history of changes to your code
  
  - the latest development version of your code is available online and you can reference it (you can even reference a specific commit number to freeze a specific version of the code)
  
  - users have a clear and transparent channel to report bugs/difficulties
  
  - it greatly facilitates collaborative development
  
  
### Upload one's package `r fontawesome::fa("r-project")` onto *GitHub*

> `r emoji::emoji("point_right")` ***Your turn !***
>
> 1. Go to [https://github.com/](https://github.com/) and create a *GitHub* account (if you hesitate, a common convention is to use your *firstnamelastname* as username)
> 2. Run `usethis::use_github()` into the `r fontawesome::fa("r-project")` console and follow the instructions.
> 3. Add a `README.Rmd` file to your package in order to have a nice home page on *GitHub*:
>    - 3a. In *RStudio*, run the command `usethis::use_readme_rmd()`
>    - 3b. using the "*Diff*" tool in the "*Git*" tab of *RStudio*, review the changes made by the previous command
>    - 3c. edit the created `README.Rmd` file, then create the corresponding `README.md`  file by running `knitr` (click on the wool ball "*Knit*" at the top left in *RStudio*), before making a 3^rd^ commit containing these changes
>    - 3d. At this point, if you visit your directory page on *GitHub*, your 3^rd^ commit does not appear for the moment. You have to synchronize the online *GitHub* directory with your local folder. To do this, you have to click on "*Push*" from the "Git" tab. Now, the changes of this 3^rd^ commit should be visible online on *GitHub.*
      
    
    

## Collaborative code production

![Artwork CC-BY Allison Horst](AdvancedRcourse_dev_perf_files/github_friends.png){width=100%}



`git` and GitHub are particularly useful and efficient when several people collaborate to develop code together. Indeed, everyone can *pull* and *push* successive changes to the code, simultaneously, while endusing to always be working on the latest version of the code. We will see different concepts useful in the case of such a collaborative work.

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
1. By pairing-up with another participant, you will each add your new buddy as a "collaborator" to your GitHub directory from the **"Settings" tab on GitHub**.
>
  2. A few moments later, the added collaborator receives an email inviting him to accept the addition (check your spam folder). Click on the link and accept.
>
  3. In *RStudio*, create a new project form `git` using the `https` url of your buddy's project.
   
### *Branches*

A useful features of `git` is *branches*. This allows you to make important changes in the changes in the code without disrupting the current operation. It is particularly useful to explore a development path that you don't know if it will be successful in the end.

By the way, you have already been using branches since the beginning of this part. Indeed, the default branch is called "*main*" (or sometimes "*master*").

Thanks to this system of branches, we obtain a tree of the different *commits* over time (where the nodes correspond to the separation of the branches).


### *Merge*
  
A so-called "*pull*" can be decomposed into 2 actions made by `git`: 
  
  1. first a *fetch*, which corresponds to downloading the online code
  
  2. immediately followed by a *merge*, which merges the local version with the downloaded changes.
  
After conducting experimental development in one branch one may want to *merge* these changes into the "master" branch for example, once the experiment has proved successful.
  
If the changes concern separate parts of the code, then *merging* can be done without any problem. On the other hand, if the two versions to be *merged* both contain changes which concern the **same lines of code** since their last **common** *commit* , then we will encounter one (or more) **conflicts**, which we will have to be manually resolved.
  

### Conflicts

Let's take the following example: the developer $D_1$ and the developer $D_2$ have both *pulled* the version v0.1 of the code at time $t$ on their respective machines. They each work independently to make changes to the code. When *pushing* his/her changes, developer $D_2$ receives an error message: 

`"Sync Error.`  
`Please resolve all conflicted files, commit, then try syncing again."`

Chaque fichier étant source de conflit a alors été automatiquement édité comme suit :
```{git, eval = FALSE}
<<<<<<< HEAD
local code
=======
online code
>>>>>>> remote
```

In order to solve the conflict, you have to manually and carefully edit each file one by one, choosing whether to keep the local or the online version of the code, before you can *commit* again, and finally successfully *push* your changes online.

> `r emoji::emoji("point_right")` ***Your turn !*** 
> 1. Edit the `README.Rmd` file of your paired buddy, then *commit* your change, and finally *push* them.
> 2. Once your buddy has modified your own `README.Rmd` modify the file on the same line (make sure by discussing it together), **WITHOUT* *pulling* your buddy's changes first! *Comment* and try to *push* these changes.
> 3. Resolve the conflict.

**NB:** In real life you want to avoid this situation and always *pull* before *pushing*, here we purposedly do the opposite for the sake of providing an example and demystifying conflicts.


### *Fork*

A *fork* allows you to create a copy of your own from an available code repository. Thus the original code will not be impacted by your changes. This is like creating a branch, and severing it from the tree, so you can assume ownership of it. It could also have been called a "cutting" to continue the metaphor...

This action is mainly useful for *pull requests* (see next).



### *Pull request*

*Pull requests* are the easiest way to propose changes in a code project which you are not a contributor of. GitHub provides a graphical interface that makes this easy to do so.

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
  1. Modify the `README.Rmd` of your neighbor who is **NOT** your paired-buddy after *forking* his package.
>
  2. Propose your change in the form of a *pull request* from their GitHub repository webpage ("Pull request"s tab).
>
  3. Accept your own neighbor *pull request* on your repository GitHub website, and then *merge* it.



### *Issues*

For any GitHub repository, you can post a comment, in the form of an *issue*, to alert the developers about a possible bug (providing a minimally reproducible example of the bug), or a question about the use of the package, or ask for an additional feature...

Ideally, you should propose a *pull request* that solves your *issue* when you can (i.e. when you have both the ability and time).

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
>  1. Use `usethis::use_github_links()` to add the following 2 lines to your package `DESCRIPTION` file:  
> `URL: http://github.com/*username*/mypkg`  
> `BugReports: http://github.com/*username*/mypkg/issues`
>
>  2. View the new changes, then *commit* them.
>
>  3. Create an *issue* on your paired buddy's project
  
  
  

## Continuous Integration (CI)

With each change, with each *commit*, there is the possibility to introduce 1 (or more) bugs that will prevent the package from passing the *CRAN* `R CMD CHECK`. If you accumulate too many of these bugs, at the time of submitting the new version to *CRAN* there could be many corrections to make. It is even more frustrating if the package passed the `R CMD CHECK` before... 

Continuous integration services allow you to *check* and test your package **automatically** after each *commit* ! In case of failure, you will receive an email informing you. A number of these services offer a (limited) free package for open-source projects. 

Another reason to use continuous integration is that it allows you to test your package on different infrastructures than yours (e.g. Windows, Ubuntu, Mac OS) and for different versions of `r fontawesome::fa("r-project")` (*current*, *devel*...)

### *GitHub Actions*

*GitHub Actions* let you launch "actions" automatically, every time you push to GitHub. The `usethis::use_github_action("check-standard")` command allows you to initialize *Github Actions* to add the `R CMD CHECK` action to your package.

> `r emoji::emoji("point_right")` ***Your turn !***
>
>  1. Run the command `usethis::use_github_action("check-standard")`, then *commit* and *push* the changes. See what happens on the GitHub webpage under the "Actions" tab.
>
>  2. Add a badge to your README.Rmd (do nott forget to `knit` it) with the code obtained in the console and *commit* (and *push*) those changes.


Have a look at the following webpage which informs about the different *GitHub Actions* available for `r fontawesome::fa("r-project")` packages: [https://github.com/r-lib/actions/blob/v2-branch/examples/README.md](https://github.com/r-lib/actions/blob/v2-branch/examples/README.md)


## Build and deploy a companion website for one's package

`pkgdown` is an `r fontawesome::fa("r-project")` package that automatically generate a nice website gathering the documentation about your package (including *Vignettes*).

> ***`r emoji::emoji("point_right")` À vous de jouer !***
> 
> 1. Executer la commande `usethis::use_pkgdown()` dans la console `r fontawesome::fa("r-project")`.
>
> 2. *Commiter* et *pusher* les changements. Rendez-vous sur l'onglet *Actions* de votre répertoire sur *GitHub* et constater les nouveautés.

> ***`r emoji::emoji("point_right")` À vous de jouer !***
> 
> Examiner les changement du fichier `DESCRIPTION` suite à l'execution des différentes commandes `usethis::use_...` précedemment.
> 
> Modifier le champ *URL* du fichier `DESCRIPTION`.

![Artwork CC-BY Allison Horst](AdvancedRcourse_dev_perf_files/usethis.png){width=100%}


## Additional References

 - [*Happy Git With R*](https://happygitwithr.com/) by Jenny Bryan.
 
 - Jennifer Bryan (2018). Excuse Me, Do You Have a Moment to Talk about Version Control? *The American Statistician* 72 (1):20--27.  
 [DOI: 10.1080/00031305.2017.1399928](https://doi.org/10.1080/00031305.2017.1399928)


## Appendix 2.1: R-hub {-}

The *R consortium* provides the [R-hub builder](https://www.r-consortium.org/blog/2016/06/06/first-public-version-of-the-r-hub-builder), and has the ambition to one day provide a continuous integration service especially dedicated to `r fontawesome::fa("r-project")` packages.

It has the advantage to use the exact same infrastructure as the `CRAN` make the *check* of your package foolproof. You can use it through the `devtools::check_rhub()` function.


## Appendix 2.2: Code coverage {-}

The `covr` package proposes a solution to measure the coverage of unit tests associated to a package. The test coverage determines the proportion of the source code that is actually used during the execution of unit tests. Measuring the coverage of the code reinforces the reliability of a code and gives more confidence to its potential users.

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
>  1. Run the command `usethis::use_coverage()`, add a nice badge to your README.md with the code you got in the R console

>  
>  2. *Commit* and *push* these changes.

For more information feel free to look at the [`covr` vignette](https://cran.r-project.org/web/packages/covr/vignettes/how_it_works.html).


<!--chapter:end:03-GitHub_versionControl.Rmd-->


# Measuring and comparing execution times

The first step before optimizing a code is to measure its execution time, in order to compare timings between different implementations.

For this section and the following we refer to the book [*Advanced R*](https://adv-r.hadley.nz/) by Hadley Wickham [^2], freely available online.

[^2]: *Advanced R* (2^nd^ Edition) by Hadley Wickham. The R series, CRC press, 2019. ISBN: 9780815384571 [https://adv-r.hadley.nz/](https://adv-r.hadley.nz/)
 
## Measuring execution times with `system.time()`

To measure the execution time of an `r fontawesome::fa("r-project")` command, you can use the native `system.time()` function like this:

```{r, echo=FALSE}
library(mypkgr)
```

```{r}
obs <- matrix(rep(1.96, 2), nrow=2, ncol=1)
system.time(mvnpdf(x=obs, Log=FALSE))
```

The problem that appears in this example is that the execution is so fast that `system.time()` displays `0` (or a very close value) that will be impossible to compare to an hopefully faster implementation. Also, we see that there is some variability when we run the command several times.

Thus if we want to compare our code with the `mvtnorm::dmvnorm()` function, we can't use `system.time()`:

```{r}
obs <- rep(1.96, 2)
system.time(mvtnorm::dmvnorm(obs))
```

We could imagine that we need to increase the complexity of our calculation to be able to compare them, but there is actually a better way: use the `microbenchmark` package !



## Compare execution times with `microbenchmark()`

As its name indicates, this package allows to compare execution times even when they are very fast. Moreover, each benchmarked expression will be repeatedly evaluated a certain number of times, thus stabilizing its timing estimations.

```{r}
library(microbenchmark)
mb <- microbenchmark(mvtnorm::dmvnorm(rep(1.96, 2)),
                     mvnpdf(x = matrix(rep(1.96,2)), Log = FALSE),
                     times = 1000)
mb
```

```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8) + 
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:2]) + 
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw()
```


Both `mvnpdf()` and `dmnvorm()` functions being able to take a matrix as input, we can also compare their speeds in this setting:

```{r}
n <- 100
mb <- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)),
                     mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), 
                            Log=FALSE),
                     times=100)
mb
```

```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:2]) + 
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw()
```


Something happened... And we will find out what exactly is causing this issue in what comes next.

<!--chapter:end:04-timing.Rmd-->


# Profiling code

```{r, echo=FALSE}
library(mypkgr)
library(microbenchmark)
library(ggplot2)
```

*Profiling* is about determining which part of the code take the most time to compute (and also memory-wise). Once you have found the block of code that takes the longest time to execute, our goal is only to optimize that small part of the code.

To get a *profiling* of the code below, select the lines of code of interest and go to the "Profile" menu then "Profile Selected Lines". It uses the package `profvis`, and in particular its `profvis()` function. 

```{r, eval=FALSE}
n <- 10e4
pdfval <- mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE)
```
```{r, echo=FALSE}
n <- 10e4
profvis::profvis(mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE))
```

*OK, OK, we get it !* Concatenating a vector as you go in a loop is really not a good idea.



## Comparison with an improved implementtation of `mnvpdf()`.

Consider a new version of `mvnpdf()`, called `mvnpdfsmart()`. Download the [file](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfsmart.R), and then include it in the package.

Now profile the following command:

```{r, eval=FALSE}
n <- 10e4
pdfval <- mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE)
```
```{r, echo=FALSE}
n <- 10e4
profvis::profvis(mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE))
```

We have indeed removed the main computational bottleneck, and we can now learn in a more detailed way what takes time in our function.

To confirm that `mvnpdfsmart()` is indeed much faster than `mvnpdf()` we can make a comparison using `microbenchmark()`:

```{r}
n <- 1000
mb <- microbenchmark(mvnpdf(x = matrix(1.96, nrow = 2, ncol = n), Log = FALSE),
                     mvnpdfsmart(x = matrix(1.96, nrow = 2, ncol = n),
                                 Log = FALSE),
                     times=100L)
mb
```

```{r, echo=FALSE}
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[2:3]) + 
  scale_y_log10(minor_breaks=brk) +
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw()
```

We can also check whether `mvnpdfsmart()` becomes competitive with `dmvnorm()`:

```{r}
n <- 1000
mb <- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)),
                     mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     times=100L)
mb
```

```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:3]) + 
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw()
```

There is still work to be done...



## Comparison with an optimized pure `r fontawesome::fa("r-project")` implementation

After several research, tests, trials and errors, Boris arrived at an [optimized version](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfoptim.R) using `r fontawesome::fa("r-project")` capabilities.

Include this `mvnpdfoptim()` function in your package, and then profile it:

```{r}
n <- 10e4
profvis::profvis(mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE))
```

And the `microbenchmark()` that goes with it:

```{r}
n <- 1000
mb <- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)),
                     mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     times=100L)
mb
```

```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:4]) +
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw()
```

Finally,  we can profile the `dmvnorm()` function:

```{r}
n <- 10e5
library(mvtnorm)
profvis::profvis(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)))
```


<!--chapter:end:05-profiling.Rmd-->


# `Rcpp` or how to easily embed `C++` code into a `r fontawesome::fa("r-project")` package

```{r, echo=FALSE}
library(mypkgr)
library(microbenchmark)
library(ggplot2)
```

`Rcpp` ("*R-C-Plus-Plus*") is a package which facilitates the interface between `C++` and `r fontawesome::fa("r-project")`. `r fontawesome::fa("r-project")` is an interpreted language, a feature that makes a number of things easy (including giving us access to the console in which we can evaluate code and variables on the fly). Nevertheless, this ease of use is counterbalanced by larger computation times comapred to lower level languages such as `C`, `Fortran` and `C++` (but which require compilation).

The curious reader is directed towards the online book [*Rcpp for everyone*](https://teuder.github.io/rcpp4everyone_en/) by Masaki E. Tsuda, which is a very thorough and complete resource for understanding how to use `Rcpp`, in complement to the introduction that can be found in the "Rcpp" section of Hadley Wickham's book [*Advanced R*](https://adv-r.hadley.nz/Rcpp.html)[^2].

[^2]: *Advanced R* (2^nd^ Edition) by Hadley Wickham. The R series, CRC press, 2019. ISBN: 9780815384571 [https://adv-r.hadley.nz/](https://adv-r.hadley.nz/)

## First function in `Rcpp`

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
> 1. To make your package ready for use with `Rcpp`, start by running the following command:
    ```{r, eval=FALSE}
    usethis::use_rcpp()
    ```
> 2. See the changes made 
> 3. You should also add the following 2 Roxygen comments in the general help page of the package, as indicated in the console:
    ```{r, eval=FALSE}
    #' @useDynLib mypkgr
    #' @importFrom Rcpp sourceCpp, .registration = TRUE
    NULL
    ```

We are now going to create a first function in `Rcpp` to invert a matrix. For this, we will use the [`C++` library `Armadillo`](https://arma.sourceforge.net/docs.html). It is a modern and simple linear algebra *library*, highly optimized, and interfaced with `r fontawesome::fa("r-project")` via the `RcppArmadillo` package.

`C++` is not a very different language from `r fontawesome::fa("r-project")`. The main differences that will have an impact for us:
  
  - `C++` is very efficient for *for* loops (including nested for loops -- `r emoji::emoji("warning")` there is often one order that is faster than the other, due to the way `C++` allocates and walks through memory).
  
  - Each command must end with a semicolon `;`.
  
  - C++ is a **typed** language: you must **declare** the type of **each variable** before you can use it in the code.


> `r emoji::emoji("point_right")` ***Your turn !*** 
> 
> 1. Create a new `C++` file from *RStudio* (via the `File` > `New File` > `C++ File` menu), and save it in the `src` folder. Take the time to read it and try to understand each line.
> 2. Compile and load your package (via the "Install and Restart" button) and try using the `timesTwo()` function from the console.
> 3. Install the `RcppArmadillo` `r emoji::emoji("point_right")` package, and don't forget to make the necessary additions to `DESCRIPTION` (use `usethis::use_rcpp_armadillo()`)
> 4. Using Hadley Wickham's [introduction to `Rcpp`](https://adv-r.hadley.nz/Rcpp.html#rcpp-intro) in his book *Advanced R*, as well as the documentation for the [`RcppArmadillo` package](https://gallery.rcpp.org/articles/armadillo-eigenvalues/) and for the `C++` library [Armadillo](https://arma.sourceforge.net/docs.html), try to write a short function `invC()` in `C++` that computes the inverse of a matrix.
> 5. When you have successfully compiled your `invC` function and it is accessible from `r fontawesome::fa("r-project")`, create a `mvnpdf_invC()` function from the `mvnpdfsmart` implementation replacing only the matrix inverse calculations with a call to `invC`.
> 6. Evaluate the performance gain of this new implementation `mvnpdf_invC`.

```{r, echo=TRUE, eval=TRUE, collapse=TRUE}
n <- 1000
mb <- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)),
                     mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdf_invC(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     times=100L)
mb
```

```{r, echo=FALSE, eval =TRUE}
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:5]) + 
  scale_y_log10(minor_breaks=c(seq(from=1, to=10, by=1), seq(from=10, to=100, by=10))) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw()
```

```{r, eval=TRUE, echo = TRUE, error = TRUE}
profvis::profvis(mvnpdfoptim(x=matrix(1.96, 
    nrow = 2, ncol = 1000), Log=FALSE))
profvis::profvis(mvnpdfoptim(x=matrix(1.96, 
    nrow = 100, ncol = 1000), Log=FALSE))
```

## Optimize thanks to `C++`

As a general rule, not much computational time is gained by replacing an optimized `r fontawesome::fa("r-project")` function with a `C++` function. Indeed, most of the `base` `r fontawesome::fa("r-project")` functions are in fact already wrappers around well optimized `C` or `Fortran` routines. The gain is then limited to the suppression of argument checking and type management (which is there for a reason!).

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
>  1. From `mvnpdfsmart`, propose a complete implementation in `C++` for computating the density of the multivariate Normal distribution `mvnpdfsmartC()`.
> 
>  2. Evaluate the performance gain of this new implementation `mvnpdfsmartC`.


You can download our proposal for `mvnpdfsmartC.cpp` [here](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfsmartC.cpp).

For (relatively small) additional speed gain (at the cost of code readability!), you can have a look at our optimized Armadillo `C++` implementation in [`mvnpdfoptimC.cpp`](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfoptimC.cpp).

```{r, echo=TRUE, eval=TRUE}
n <- 1000
mb <- microbenchmark(mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)),
                     mvnpdf(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfsmart(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdf_invC(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
                     mvnpdfsmartC(x=matrix(1.96, nrow = 2, ncol = n), mean = rep(0, 2), varcovM = diag(2), Log=FALSE),
                     mvnpdfoptimC(x=matrix(1.96, nrow = 2, ncol = n), mean = rep(0, 2), varcovM = diag(2), Log=FALSE),
                     times=100L)
mb
```

```{r, echo=FALSE, eval=TRUE}
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  viridis::scale_fill_viridis(guide="none", discrete=TRUE) + 
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw() 
```

Note that `Rcpp` functions can be used outside of a package architecture thanks to the `Rcpp::sourceCpp()` function. But, as we have seen that it is always desirable to manage all of one's code inside a package, it is unlikely that you will need this !

## Annexe 5.1: premature optimization is a bad idea {-}

Chambers, *Software for Data Analysis: Programming with R*, Springer, 2008:

> *"Including additional C code is a serious step, with **some added dangers** and often a **substantial amount of programming and debugging** required. **You should have a good reason.**"*

<!--chapter:end:06-Rcpp.Rmd-->

# R code Parallelization

## Introduction to parallel execution in `r fontawesome::fa("r-project")`

Apart from optimizing the code and the algorithms, another way to get a high performing code is to take advantage of the parallel architectures of modern computers. The goal is then to **parallelize** one's code in order to perform simultaneous operations on distinct parts of the same problem, using different computing cores. This does not reduce the total computation time needed, but the set of operations is executed faster, resulting in overall user speed-up.

There is a significant number of algorithms that are so-called "*embarrassingly parallel*", i.e. whose computations can be broken down into several independent sub-computations. In statistics, it is often easy and straightforward to parallelize according to different observations or different dimensions. Typically, these are operations that can be written in the form of a loop whose operations are independent from one iteration to the next.

**The necessary operations to execute code in parallel are as follows:**

  1. Start $m$ "worker" processes (i.e. computing cores) and initialize them
  
  2. Send the necessary functions and data for each task to the workers
  
  3. Split the tasks into $m$ operations of similar size and send them to the workers
  
  4. Wait for all workers to finish their calculations
  
  5. Collect the results from the different workers
  
  6. Stop the worker processes


Depending on the platform, several communication protocols are available between the cores. Under UNIX systems, the *Fork* protocol is the most used, but it is not available under Windows where the *PSOCK* protocol is used instead. Finally, for distributed computing architecture where the cores are not necessarily on the same physical processor, the *MPI* protocol is generally used. The advantage of the `future` and `future.apply` package is that the same code can be executed whatever the hardware configuration.

Since `R 2.14.0`, the `parallel` package is directly included in `r fontawesome::fa("r-project")` and allows to start and stop a cluster of several worker processes (step 1 and 6). In addition to the `parallel` package, we will use the `future` package which allows to manage the worker processes and the communication and articulation with the `future.apply` package, which in turn allows to manage the dialogue with the workers (sending, receiving and collecting the results -- steps 2, 3, 4 and 5).



## First `r fontawesome::fa("r-project")` parallel function 

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
> Start by writing a simple function that computes the logarithm of $n$ numbers:
>
>  1. Determine how many cores are available on your computer with the function `future::availableCores()`.
>
>  2. Using the function `future::plan(multisession(workers = XX))`, declare a "*plan*" of parallel computations on your computer (taking care to **always leave at least one core available** to handle other processes).
>
>  3. Using one of the *\*apply* functions `future.apply::future_*apply()`, compute the log of $n$ numbers in parallel and concatenate the results into a vector.
>
>  4. Compare the execution time with that of a sequential function on the first 100 integers, using the command :  
`microbenchmark(log_par(1:100), log_seq(1:100), times=10)`


```{r echo = TRUE, message = FALSE, cache=TRUE}
library(microbenchmark)
library(future.apply)

log_seq <- function(x){
  # try this yourself (spoiler alert: it is quite long...):
  # res <- numeric(length(x))
  # for(i in 1:length(x)){
  #   res[i] <- log(x[i])
  # }
  # return(res)
  return(log(x))
}

log_par <- function(x){
  res <- future_sapply(1:length(x), FUN = function(i) {
    log(x[i])
  })
  return(res)
}

plan(multisession(workers = 3))
mb <- microbenchmark(log_par(1:100), log_seq(1:100), times = 50)
```


```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:4]) + 
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw() +
  ggtitle("Spoiler alert")
```

The parallel version runs much slower... Because in fact, if the individual tasks are too fast, `r fontawesome::fa("r-project")` will spend more time communicating with the cores than doing the actual computations.

**A loop iteration must be relatively long for parallel computing to provide a significant gain in computation time!**

By increasing $n$, we observe a reduction in the difference between the 2 implementations (the parallel computation time increases very slowly compared to the increase of the sequential function).

<!--**NB:** the iterators of the `itertools` package are very efficient to minimize the number of communications between cores, but can only be used when the code inside `future_*apply()` is vectorized (it is always possible to vectorize the code inside, for example with a function of type `apply`).-->




## Efficient parallelization

We will now look at another use case. Let's say we have a large array of data with 10 observations for 100,000 variables (e.g. genetic measurements), and we want to compute the median for each of these variables.

```{r}
x <- matrix(rnorm(1e6), nrow = 10)
dim(x)
```

For an experienced `r fontawesome::fa("r-project")` user, such an operation is easily implemented using `apply()`:

```{r}
colmedian_apply <- function(x){
  return(apply(x, 2, median))
}
system.time(colmedian_apply(x))
```

In reality, a (good) `for` loop is no slower -- provided it is nicely programmed:

```{r}
colmedian_for <- function(x){
  ans <- rep(0, ncol(x)) 
  for (i in 1:ncol(x)) {
    ans[i] <- median(x[, i]) 
  }
  return(ans)
}
system.time(colmedian_for(x))
```



> `r emoji::emoji("point_right")` ***Your turn !*** 
> Try to further improve this computation time by parallelizing your code for each of the 100,000 variables. Is there a gain in computation time?

<!-- 2. Propose an alternative implementation using the `itertools::isplitIndices()` function which allows you to separate your data (the $n$ numbers) into as many groups (or batchs) as you have cores. Compare again the computation times.
-->

```{r, error=TRUE, cache=TRUE}
colmedian_par <- function(x){
  res <- future_sapply(1:ncol(x), FUN = function(i) {
          median(x[, i])
    })
  return(res)
}
plan(multisession(workers = 3))
system.time(colmedian_par(x))

mb <- microbenchmark(colmedian_apply(x), 
                     colmedian_for(x),
                     colmedian_par(x), 
                     times = 10)
mb
```

```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^9, "Expression" = mb$expr)
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:4]) + 
  #scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (sec)") +
  xlab("Computed expression") +
  #annotation_logticks(sides="l") +
  theme_bw() +
  ylim(0, max(data2plot$Time)) +
  ggtitle("Parallelizing works! 3 cores used for parallle computations")
```

<!--
###  Iterators

The `itertools` package allows to easily split data or tasks (step 3) while minimizing communication with different workers. It is based on an implementation of iterators in `r fontawesome::fa("r-project")`. However, its use requires vectorizing the code inside `future_*apply()`. Experiment with the small code below: 

```{r, error = TRUE}
myiter <- itertools::isplitIndices(n = 30, chunks = 3)

# a first time
iterators::nextElem(myiter)
# a second time... Oh ?!
iterators::nextElem(myiter)
# again !
iterators::nextElem(myiter)
# again ?
iterators::nextElem(myiter)
```
-->

### Other "plans" for parallel computations

To run your code (exactly the same code, this is one of the advantages of the `future*` family packages), you need to set up a "plan" of computations:

- On a computer (or a single computer server) under Unix (Linux, Mac OS), you can use `plan(multicore(workers = XX))` which is often more efficient. The `multisession` plan always works.

- on a HPC cluster (like CURTA in Bordeaux), we refer to the package [`future.batchtools`](https://cran.r-project.org/web/packages/future.batchtools/vignettes/future.batchtools.html)



## Parallelization in our common theme example

> `r emoji::emoji("point_right")` ***Your turn !*** 
>
>  1. From the function `mvnpdfoptim()` and/or `mvnpdfsmart()`, propose an implementation parallelizing the computations on the observations (columns of $x$)
>  
>  2. Compare the execution times for 10 000 observations


```{r, cache=TRUE}
plan(multisession(workers = 3))
n <- 10000
mb <- microbenchmark::microbenchmark(
  mvtnorm::dmvnorm(matrix(1.96, nrow = n, ncol = 2)),
  mypkgr::mvnpdfoptim(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
  mypkgr::mvnpdfoptim_par(x=matrix(1.96, nrow = 2, ncol = n), Log=FALSE),
  times=20)
mb
```

```{r, echo=FALSE}
library(ggplot2)
data2plot <- cbind.data.frame("Time" = mb$time/10^6, "Expression" = mb$expr)
rangeTime <- c(floor(log10(min(data2plot$Time))):ceiling(log10(max(data2plot$Time))))
brk <- NULL
for(i in rangeTime){
    brk <- c(brk, seq(from = 10^i, to = 10^(i+1), by=10^i))
}
levels(data2plot$Expression) <- gsub("mvtnorm::", "", sapply(strsplit(levels(data2plot$Expression), "(", fixed=T), "[", 1))
ggplot(data2plot) + geom_violin(aes(x=Expression, y=Time, fill=Expression), alpha=0.8)  +
  scale_fill_manual(guide="none", values=viridis::viridis(6)[1:4]) + 
  scale_y_log10(minor_breaks=brk) + 
  ylab("Execution timings (milli-sec)") +
  xlab("Computed expression") +
  annotation_logticks(sides="l") +
  theme_bw() +
  ggtitle("Spoiler alert 2")
```

You can download our proposed implementation for `mvnpdfoptim_par` [here](https://heavyr.borishejblum.science/AdvancedRcourse_dev_perf_files/mvnpdfoptim_par.R).


## Conclusion

Parallel computation saves time, but first you have to optimize your code. When parallelizing a code, the gain on the execution time depends above all on the ratio between the communication time and the effective computation time for each task.

<!--chapter:end:07-parallelisation.Rmd-->

<!--
# Miscelaneouus

## Debugging with `browser()`

## `attach`

## memory management

## copies and local/global variables in functions

## naming

## `gpplot2`


-->

<!--chapter:end:08-misc.Rmd-->


# *Take-home message(s)*

 1. **MAKE PACKAGES!**
 
 2. use `git`, at least locally for yourself
 
 3. **if needed** (i.e. after optimization of `r fontawesome::fa("r-project")` code itself), do not be afraid of using `Rcpp` and/or of parallelizing your code

<!--chapter:end:09-TakeHome.Rmd-->


# Further reading {-}

  - Hadley Wickham's online books are truly excellent and contain a lot of supplementary information to what we have covered in this training:
  
    - the website on writing packages [*R packages*](https://r-pkgs.org/).
    
    - the website [*Advanced R*](https://adv-r.hadley.nz/) for everything regarding optimization, `Rcpp`, or parallel computing.
    
    - the website [*R for Data Science*](https://r4ds.hadley.nz/) is also quite comprehensive and includes chapters on data management in `r fontawesome::fa("r-project")`, but also on  structures in `r fontawesome::fa("r-project")`, modeling, as well as elements on graphics and `Quarto`.
    
  - the online book [Rcpp for everyone](https://teuder.github.io/rcpp4everyone_en/) by Masaki E. Tsuda is also very good. 




<!--chapter:end:10-further_reading.Rmd-->

